<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> [Papers] Learning a model of facial shape and expression from 4D scans (SIGGRAPH 2017) | owei </title> <meta name="author" content="owei "> <meta name="description" content="Paper Review"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%96%A4&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://oweixx.github.io/blog/2025/papers_FLAME/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">owei</span> </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">[Papers] Learning a model of facial shape and expression from 4D scans (SIGGRAPH 2017)</h1> <p class="post-meta"> Created on November 16, 2025 </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/tag/paper"> <i class="fa-solid fa-hashtag fa-sm"></i> Paper</a>   ·   <a href="/blog/category/paper"> <i class="fa-solid fa-tag fa-sm"></i> Paper</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <h2 id="learning-a-model-of-facial-shape-and-expression-from-4d-scans">Learning a model of facial shape and expression from 4D scans</h2> <h3 id="papergithubproject"> <a href="https://dl.acm.org/doi/10.1145/3130800.3130813" rel="external nofollow noopener" target="_blank">[Paper]</a><a href="https://github.com/soubhiksanyal/FLAME_PyTorch" rel="external nofollow noopener" target="_blank">[Github]</a><a href="https://flame.is.tue.mpg.de/" rel="external nofollow noopener" target="_blank">[Project]</a> </h3> <blockquote> <p><strong>Title:</strong> Learning a model of facial shape and expression from 4D scans<br> <strong>Journal name &amp; Publication Date:</strong> SIGGRAPH 2017-11-16<br> <strong>Authors:</strong> Tianye Li, Timo Bolkart, Michael J. Black</p> </blockquote> <hr> <blockquote> <h2 id="1-abstract--introduction">1. Abstract &amp; Introduction</h2> </blockquote> <p>3D Face Modeling에서 face capture를 통한 아주 detail한 face reconstruction 방법이 있지만 이는 종종 mesh를 제대로 구현하지 못하는 artifacts들이 발생한다. (맨 위의 그림) 반대로 low resolution일 경우 face expression에 대한 표현이 제대로 이루어지지 못하는 현상이 발생하게 된다. (맨 아래) 해당 논문에서는 이 지점들의 middle ground를 목표로 하는 FLAME model (Faces Learned with an Articulated Model and Expressions)를 제안한다.</p> <p><img src="https://velog.velcdn.com/images/lowzxx/post/373cfb1e-268a-48fa-9b94-1a532e10d947/image.png" alt=""></p> <ul> <li>FLAME은 low-dimensional이지만 기존의 FaceWarehouse, Basel face model보다 more expressive한 FLAME Model을 제안한다.</li> <li>FLAME Model은 더 정확하며 추후 연구에 활용될 수 있게 더 적합한 모델이다.</li> <li>Face mesh model을 parameterization하여 더 유연하게 다룰 수 있게 만들었다.</li> </ul> <hr> <blockquote> <h2 id="3-model-formulation">3. Model Formulation</h2> </blockquote> <p><img src="https://velog.velcdn.com/images/lowzxx/post/49220311-d522-4d52-8ee3-2097b6f0450c/image.png" alt=""></p> <p>Flame mesh model은 기본적으로 SMPL model formulation을 따른다. SMPL이 Facial에 집중적으로 formulation 되어 있지는 않지만, 이를 이용하면 더 computationally efficient하며 더 경쟁력 있는 부분이라 사용했다고 한다.</p> <p>Flame은 정확한 blendshapes을 위해 linear blend skinning(LBS)를 사용하고 $N = 5023$ 개의 vertices(정점), $K = 4$ 개의 joints(neck, jaw and eyeballs)을 사용한다고 한다.</p> <p><img src="https://velog.velcdn.com/images/lowzxx/post/7041c752-51ac-4538-9ee9-e9a101bcd712/image.png" width="900"></p> <blockquote> <h3 id="parameter-descrition">Parameter descrition</h3> <ul> <li> <strong>shape coefficients:</strong> $\vec\beta \in \R^{\left\vert \vec\beta \right\vert}$</li> <li> <strong>pose coefficients:</strong> $\vec\theta \in \R^{\left\vert \vec\theta \right\vert}$</li> <li> <strong>expression coefficients:</strong> $\psi \in \R^{\left\vert \vec\psi \right\vert}$</li> <li>$J(\vec{\beta})$: shape에 따라 달라지는 joint 위치</li> <li>$\mathcal{W}$: 각 vertex에 대한 skinning weight 행렬</li> </ul> </blockquote> <p>아래는 최종 FLAME Model에 대한 equation이다. $$ T_P(\vec{\beta}, \vec{\theta}, \vec{\psi}) = \bar{T}</p> <ul> <li>B_S(\vec{\beta}; \mathcal{S})</li> <li>B_P(\vec{\theta}; \mathcal{P})</li> <li>B_E(\vec{\psi}; \mathcal{E}). $$ 해당 부분 부터 보자면, 기본 모델 $\bar{T}$에서 model을 변형하는 parameter shape, pose, expression에 대한 parameter들을 통해 blendshape을 하여 변형된 model을 반환하게 된다.</li> </ul> <p>\(M(\vec{\beta}, \vec{\theta}, \vec{\psi}) = W\big(T_P(\vec{\beta}, \vec{\theta}, \vec{\psi}), J(\vec{\beta}), \vec{\theta}, \mathcal{W}\big),\) 그렇게 반환된 mesh model $T_P$는 관절 위치 Joint와 관절 회전, blendshape 가중치와 함께 최종 모델로 변환이 된다.</p> <p>여기까지는 매우 간단한 설명이었고, 이후 부터는 해당 model을 직접적으로 변형하는 blendshape에 대한 설명이다. 해당 부분에 대해서는 직접적으로 이해가 되는 부분들이 많지 않아서 gpt와 함께 확인하였다.</p> <h3 id="blendshapes">blendshapes</h3> <p><strong>Shape blendshapes</strong> $$ B_S(\vec{\beta}; \mathcal{S}) = \sum_{n=1}^{|\beta|} \beta_n \, \mathbf{S}_n,</p> <p>\(\) \vec{\beta} = [\beta_1, \dots, \beta_{|\beta|}]^\mathsf{T}, \quad \mathcal{S} = [\mathbf{S}<em>1, \dots, \mathbf{S}</em>{|\beta|}] \in \mathbb{R}^{3N \times |\beta|}. $$ $\vec{\beta}$는 사람의 얼굴형을 결정하는 shape coefficient이고 $\mathbf{S}$는 n번째 vertices의 basis로 각 basis 방향으로 $\beta_n$만큼의 이동하는 형태를 의미한다.</p> <p><strong>Pose blendshapes</strong></p> <p>\(R(\vec{\theta}) : \mathbb{R}^{|\theta|} \to \mathbb{R}^{9K},\) 회전 함수 $R(\vec\theta)$ joint의 회전 행렬 요소들을 한 벡터로 정의한다.</p> \[B_P(\vec{\theta}; \mathcal{P}) = \sum_{n=1}^{9K} \big( R_n(\vec{\theta}) - R_n(\vec{\theta}^\ast) \big)\, \mathbf{P}_n,\] \[\mathcal{P} = [\mathbf{P}_1, \dots, \mathbf{P}_{9K}] \in \mathbb{R}^{3N \times 9K}.\] <p>zero pose를 의미하는 $R_n(\vec{\theta}^\ast)$와 현재포즈 사이에서의 차이를 통해 얼마나 회전 행렬이 바뀌었는지를 계산하고, 회전 요소가 변할 때 생기는 vertex 보정 $\mathbf{P}_n$을 선형조합해 Pose를 표현하게 된다.</p> <p><strong>Expression blendshapes</strong> Expression blendshape은 “웃음, 찡그림, 놀람”과 같은 표정의 표현에 대한 부분이고 <strong>non-rigid facial deformation</strong>을 설명하는 pose와 독립적인 공간이다.</p> \[B_E(\vec{\psi}; \mathcal{E}) = \sum_{n=1}^{|\psi|} \psi_n \, \mathbf{E}_n,\] <p>$\mathbf{E}_n$은 특정 표정 방향에 해당하는 expression basis에 해당하여 여러 표정 basis들을 가중치로 섞어서 만든 expression deformation을 의미하는 blendshape이다.</p> \[\vec{\psi} = [\psi_1, \dots, \psi_{|\psi|}]^\mathsf{T}, \quad \mathcal{E} = [\mathbf{E}_1, \dots, \mathbf{E}_{|\psi|}] \in \mathbb{R}^{3N \times |\psi|}.\] <p>$\mathcal{E}$는 orthonormal expression basis를 의미한다고 한다.</p> <hr> <blockquote> <h2 id="4-temporal-registration">4. Temporal Registration</h2> </blockquote> <h3 id="initial-model">Initial model</h3> <h3 id="single-frame-registration">Single-frame registration</h3> <h3 id="sequential-registration">Sequential registration</h3> <hr> <blockquote> <h2 id="-supplementray">+ Supplementray</h2> </blockquote> <hr> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/papers_3dgaussian/">[Papers] 3D Gaussian Splatting for Real-Time Radiance Field Rendering (SIGGRAPH 2023)</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/papers_viton/">[Papers] VITON: An Image-based Virtual Try-on Network (IEEE 2018)</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/papers_nerf/">[Papers] NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis (ECCV 2020)</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/papers_multiply/">[Papers] Multiply: Reconstruction of Multiple People from Monocular Video in the Wild (CVPR 2024)</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/papers_detr/">[Papers] DETR: End-to-End Object Detection with Transformers (CVPR 2020)</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 owei . Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> </body> </html>