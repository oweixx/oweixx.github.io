<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> [Papers] Learning a model of facial shape and expression from 4D scans (SIGGRAPH 2017) | owei </title> <meta name="author" content="owei "> <meta name="description" content="Paper Review"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%96%A4&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://oweixx.github.io/blog/2025/papers_FLAME/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">owei</span> </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">[Papers] Learning a model of facial shape and expression from 4D scans (SIGGRAPH 2017)</h1> <p class="post-meta"> Created on November 16, 2025 </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/tag/paper"> <i class="fa-solid fa-hashtag fa-sm"></i> Paper</a>   ·   <a href="/blog/category/paper"> <i class="fa-solid fa-tag fa-sm"></i> Paper</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <h2 id="learning-a-model-of-facial-shape-and-expression-from-4d-scans">Learning a model of facial shape and expression from 4D scans</h2> <h3 id="papergithubproject"> <a href="https://dl.acm.org/doi/10.1145/3130800.3130813" rel="external nofollow noopener" target="_blank">[Paper]</a><a href="https://github.com/soubhiksanyal/FLAME_PyTorch" rel="external nofollow noopener" target="_blank">[Github]</a><a href="https://flame.is.tue.mpg.de/" rel="external nofollow noopener" target="_blank">[Project]</a> </h3> <blockquote> <p><strong>Title:</strong> Learning a model of facial shape and expression from 4D scans<br> <strong>Journal name &amp; Publication Date:</strong> SIGGRAPH 2017-11-16<br> <strong>Authors:</strong> Tianye Li, Timo Bolkart, Michael J. Black</p> </blockquote> <hr> <blockquote> <h2 id="1-abstract--introduction">1. Abstract &amp; Introduction</h2> </blockquote> <p>3D Face Modeling에서 face capture를 통한 아주 detail한 face reconstruction 방법이 있지만 이는 종종 mesh를 제대로 구현하지 못하는 artifacts들이 발생한다. (맨 위의 그림) 반대로 low resolution일 경우 face expression에 대한 표현이 제대로 이루어지지 못하는 현상이 발생하게 된다. (맨 아래) 해당 논문에서는 이 지점들의 middle ground를 목표로 하는 FLAME model (Faces Learned with an Articulated Model and Expressions)를 제안한다.</p> <p><img src="https://velog.velcdn.com/images/lowzxx/post/373cfb1e-268a-48fa-9b94-1a532e10d947/image.png" alt=""></p> <ul> <li>FLAME은 low-dimensional이지만 기존의 FaceWarehouse, Basel face model보다 more expressive한 FLAME Model을 제안한다.</li> <li>FLAME Model은 더 정확하며 추후 연구에 활용될 수 있게 더 적합한 모델이다.</li> <li>Face mesh model을 parameterization하여 더 유연하게 다룰 수 있게 만들었다.</li> </ul> <hr> <blockquote> <h2 id="3-model-formulation">3. Model Formulation</h2> </blockquote> <p><img src="https://velog.velcdn.com/images/lowzxx/post/49220311-d522-4d52-8ee3-2097b6f0450c/image.png" alt=""></p> <p>Flame mesh model은 기본적으로 SMPL model formulation을 따른다. SMPL이 Facial에 집중적으로 formulation 되어 있지는 않지만, 이를 이용하면 더 computationally efficient하며 더 경쟁력 있는 부분이라 사용했다고 한다.</p> <p>Flame은 정확한 blendshapes을 위해 linear blend skinning(LBS)를 사용하고 $N = 5023$ 개의 vertices(정점), $K = 4$ 개의 joints(neck, jaw and eyeballs)을 사용한다고 한다.</p> <p><img src="https://velog.velcdn.com/images/lowzxx/post/7041c752-51ac-4538-9ee9-e9a101bcd712/image.png" width="900"></p> <blockquote> <h3 id="parameter-descrition">Parameter descrition</h3> <ul> <li> <strong>shape coefficients:</strong> $\vec\beta \in \R^{\left\vert \vec\beta \right\vert}$</li> <li> <strong>pose coefficients:</strong> $\vec\theta \in \R^{\left\vert \vec\theta \right\vert}$</li> <li> <strong>expression coefficients:</strong> $\psi \in \R^{\left\vert \vec\psi \right\vert}$</li> <li>$J(\vec{\beta})$: shape에 따라 달라지는 joint 위치</li> <li>$\mathcal{W}$: 각 vertex에 대한 skinning weight 행렬</li> </ul> </blockquote> <p>아래는 최종 FLAME Model에 대한 equation이다. $$ T_P(\vec{\beta}, \vec{\theta}, \vec{\psi}) = \bar{T}</p> <ul> <li>B_S(\vec{\beta}; \mathcal{S})</li> <li>B_P(\vec{\theta}; \mathcal{P})</li> <li>B_E(\vec{\psi}; \mathcal{E}). $$ 해당 부분 부터 보자면, 기본 모델 $\bar{T}$에서 model을 변형하는 parameter shape, pose, expression에 대한 parameter들을 통해 blendshape을 하여 변형된 model을 반환하게 된다.</li> </ul> \[M(\vec{\beta}, \vec{\theta}, \vec{\psi}) = W\big(T_P(\vec{\beta}, \vec{\theta}, \vec{\psi}), J(\vec{\beta}), \vec{\theta}, \mathcal{W}\big),\] <p>그렇게 반환된 mesh model $T_P$는 관절 위치 Joint와 관절 회전, blendshape 가중치와 함께 최종 모델로 변환이 된다.</p> <p>여기까지는 매우 간단한 설명이었고, 이후 부터는 해당 model을 직접적으로 변형하는 blendshape에 대한 설명이다. 해당 부분에 대해서는 직접적으로 이해가 되는 부분들이 많지 않아서 gpt와 함께 확인하였다.</p> <h3 id="blendshapes">blendshapes</h3> <p><strong>Shape blendshapes</strong> $$ B_S(\vec{\beta}; \mathcal{S}) = \sum_{n=1}^{|\beta|} \beta_n \, \mathbf{S}_n,</p> <p>\(\) \vec{\beta} = [\beta_1, \dots, \beta_{|\beta|}]^\mathsf{T}, \quad \mathcal{S} = [\mathbf{S}<em>1, \dots, \mathbf{S}</em>{|\beta|}] \in \mathbb{R}^{3N \times |\beta|}. $$ $\vec{\beta}$는 사람의 얼굴형을 결정하는 shape coefficient이고 $\mathbf{S}$는 n번째 vertices의 basis로 각 basis 방향으로 $\beta_n$만큼의 이동하는 형태를 의미한다.</p> <p><strong>Pose blendshapes</strong></p> <p>\(R(\vec{\theta}) : \mathbb{R}^{|\theta|} \to \mathbb{R}^{9K},\) 회전 함수 $R(\vec\theta)$ joint의 회전 행렬 요소들을 한 벡터로 정의한다.</p> \[B_P(\vec{\theta}; \mathcal{P}) = \sum_{n=1}^{9K} \big( R_n(\vec{\theta}) - R_n(\vec{\theta}^\ast) \big)\, \mathbf{P}_n,\] \[\mathcal{P} = [\mathbf{P}_1, \dots, \mathbf{P}_{9K}] \in \mathbb{R}^{3N \times 9K}.\] <p>zero pose를 의미하는 $R_n(\vec{\theta}^\ast)$와 현재포즈 사이에서의 차이를 통해 얼마나 회전 행렬이 바뀌었는지를 계산하고, 회전 요소가 변할 때 생기는 vertex 보정 $\mathbf{P}_n$을 선형조합해 Pose를 표현하게 된다.</p> <p><strong>Expression blendshapes</strong> Expression blendshape은 “웃음, 찡그림, 놀람”과 같은 표정의 표현에 대한 부분이고 <strong>non-rigid facial deformation</strong>을 설명하는 pose와 독립적인 공간이다.</p> \[B_E(\vec{\psi}; \mathcal{E}) = \sum_{n=1}^{|\psi|} \psi_n \, \mathbf{E}_n,\] <p>$\mathbf{E}_n$은 특정 표정 방향에 해당하는 expression basis에 해당하여 여러 표정 basis들을 가중치로 섞어서 만든 expression deformation을 의미하는 blendshape이다.</p> \[\vec{\psi} = [\psi_1, \dots, \psi_{|\psi|}]^\mathsf{T}, \quad \mathcal{E} = [\mathbf{E}_1, \dots, \mathbf{E}_{|\psi|}] \in \mathbb{R}^{3N \times |\psi|}.\] <p>$\mathcal{E}$는 orthonormal expression basis를 의미한다고 한다.</p> <hr> <blockquote> <h2 id="4-temporal-registration">4. Temporal Registration</h2> </blockquote> <h3 id="initial-model">Initial model</h3> <p>FLAME model은 shape ${\bar{T},\mathcal{S}}$, pose ${\mathcal{P}, \mathcal{W}, \mathcal{J}}$, expression $\mathcal{E}$ parameter들을 통해 변형이 되기 때문에 이들에게 일관성있게 변화해야한다.</p> <p><strong>Shape</strong> 초반의 initial model을 만들기 위해 SMPL의 full-body model에서 head model을 refined하여 이용하였다고 한다. 더 안정적이고 visual quality를 위해 눈 양쪽에 eyeball을 추가하여 현실성과 디테일을 더하였다.</p> <p><strong>Pose</strong> blendweights $\mathcal{W}$와 joint regressor$\mathcal{J}$는 사용자에 의해 정해지며, eyeball의 pose는 기본적으로 geometric center에 해당하는 pose로 initial된다.</p> <p><strong>Expression</strong> expression parameter $\mathcal{E}$를 초기화하기 위해 기본 head와 artist generated FACS-based blendshape과 비교하여 초기화를 하고, deformation transfer를 통해 model 변환을 하게 된다.</p> <h3 id="single-frame-registration">Single-frame registration</h3> <p>위에서 정의한 FLAME Model을 실제 3D Scan, Multi-View image에 대하여 어떻게 맞추는지에 대한 일련의 과정을 설명한다.</p> <p><strong>Our model-baed registration of a face scan consists of three steps.</strong> <strong>Model-only -&gt; Coupled -&gt; Texture-based</strong></p> <p><strong>1. Model-only</strong></p> \[E(\vec{\beta}, \vec{\theta}, \vec{\psi}) = E_D + \lambda_L E_L + E_P.\] <p>먼저 model coefficients만을 이용하여 scan과 landmark가 잘 맞을 수 있게 대략적인 optimizing을 하는 단계이다.</p> \[E_D = \lambda_D \sum_{v_s \in \mathcal{S}} \rho \!\left( \min_{v_m \in \mathcal{M}(\vec{\beta}, \vec{\theta}, \vec{\psi})} \left\| v_s - v_m \right\|_2 \right),\] <p>스캔의 각 점을 FLAME mesh 표면에 closest point로 매칭시키고 robust penalty를 걸어 outlier에 강건할 수 있게 한다.</p> \[E_L = \sum_{i=1}^{N_L} \left\| \Pi\!\big(\mathbf{v}_i(\vec{\beta}, \vec{\theta}, \vec{\psi})\big) - \mathbf{l}_i \right\|_2^2,\] <p>multi-view에서 landmark가 잘 align 되도록 하는 역할을 한다.</p> \[E_P = \lambda_{\theta} E_{\theta} + \lambda_{\beta} E_{\beta} + \lambda_{\psi} E_{\psi},\] <p>Prior term $E_P$에서는 파라미터들이 너무 큰 값으로 튀지 않게 정규항을 사용한다.</p> <p><strong>2. Coupled</strong></p> \[E(T, \vec{\beta}, \vec{\theta}, \vec{\psi}) = E_D + E_C + E_R + E_P.\] <p>이번엔 model이 설명하지 못하는 부분에 대하여 T가 deform될 수 있도록 하는 부분이다.</p> \[E_C = \sum_{e} \lambda_e \left\| T_e - M(\vec{\beta}, \vec{\theta}, \vec{\psi})_e \right\|_2^2,\] <p>단순히 vertex의 위치 차이를 줄이는 것 보다 edge 차이를 줄이는 것을 optimize objective로 두어 더 자연스럽고 매끄러운 deformation을 할 수 있게 한다.</p> \[E_R = \sum_{k} \lambda_k \left\| U(\mathbf{v}_k) \right\|_2^2,\] \[U(\mathbf{v}_k) = \frac{1}{|\mathcal{N}(k)|} \sum_{r \in \mathcal{N}(k)} (\mathbf{v}_r - \mathbf{v}_k),\] <p>outlier, fold-over나 찌그러지는 현상을 피하고, noisy regularization을 위해 사용한다.</p> <p><strong>3. Texture-based</strong></p> \[E(T, \vec{\beta}, \vec{\theta}, \vec{\psi}) = E_D + E_C + \lambda_T E_T + E_R + E_P.\] <p>앞에 두 단계에서는 geometry (scan, landmark)기반의 optimize 기반이의 과정이었다. 실제 detail에 관한 부분을 보강하고 expression/pose를 더 정밀하게 optimize한다.</p> \[E_T = \sum_{l = 0}^{L-1} \sum_{v = 1}^{V} \left\| \Gamma\!\big(I_l^{(v)}\big) - \Gamma\!\big(\hat{I}_l^{(v)}\big) \right\|_F^2,\] <p>직관적으로는 실제 이미지와 렌더된 이미지가 비슷해지도록 template parameter들을 조정하고, 해당 과정을 coarse level에서 큰 misalignment를 먼저 맞추고 finer level에서 detail들을 refine할 수 있게 유도한다.</p> <h3 id="sequential-registration">Sequential registration</h3> <p>여기서는 두 section으로 나뉜다. Personalization에서 개인화된 template을 생성하고, Sequence fitting에서 해당 template을 부드럽게 프레임별로 움직일 수 있도록 해준다.</p> <p><strong>Personalization</strong> multiple sequence에서 neutral pose, expression을 구하기 위해 $T_i$의 average를 구한다. 그다음 neutral result결과 중 하나의 $T_i$를 랜덤으로 골라 UV texture map을 만들고 이는 나중에 texture-based registration에서 사용된다.</p> <p><strong>Sequence fitting</strong> 간단하게 말해 그 template을 고정한 채, 이전 프레임 결과로 초기화된 single-frame registration을 프레임마다 반복해서 시간적으로 일관성을 가진 4D Face sequences를 등록하게 된다.</p> <hr> <hr> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/papers_GaussianAvatars/">[Papers] GaussianAvatars: Photorealistic Head Avatars with Rigged 3D Gaussians (CVPR 2024 Highlight)</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/papers_3dgaussian/">[Papers] 3D Gaussian Splatting for Real-Time Radiance Field Rendering (SIGGRAPH 2023)</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/papers_viton/">[Papers] VITON: An Image-based Virtual Try-on Network (IEEE 2018)</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/papers_nerf/">[Papers] NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis (ECCV 2020)</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/papers_multiply/">[Papers] Multiply: Reconstruction of Multiple People from Monocular Video in the Wild (CVPR 2024)</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 owei . Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> </body> </html>